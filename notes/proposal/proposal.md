# Project Proposal

Topic: Using SAE features to perform activation steering

<!-- Group member(s) -->

Group Members: Ev≈æen Wybitul (ewybitul@ethz.ch), Joshua Gilligan (jgilligan@ethz.ch)

<!-- Project advisor(s) -->

Project Advisors: Elliott Ash (elliott.ash@gess.ethz.ch)

<!-- Short description of the topic, data to be used, and broad approach. -->

## Outline

Activation steering [@rimskySteeringLlamaContrastive2024; @turnerActivationAdditionSteering2023] is a technique for modifying model behavior by adding a steering vector into the activations of certain layers. This approach can adjust the model's level of sycophancy, its tendency to reject requests, or its propensity hallucinate, for example, with minimal impact on overall performance. However, current steering methods require a substantial dataset of text snippets showcasing both desired and undesired behaviors to calculate the steering vectors.

Our research will aim to explore the relationship between Sparse Auto-Encoder (SAE) features and steering vectors, potentially enabling the computation of steering vectors directly from SAE features without additional data. This advancement could both simplify the process of activation steering and shed light on the characteristics of SAE features.

We propose the following plan:

1. Replicate the steering vector computation method by Rimsky et al. [@rimskySteeringLlamaContrastive2024] on the GPT-2 small model. The method utilizes both existing snippet datasets and new snippets generated by GPT-4.
2. Examine the relationship between the steering vectors obtained and the SAE features of GPT-2 small. Specifically, we will aim to:
    - Determine if steering vectors can be derived from SAE features.
    - Identify other potential steering vectors using this method.
    - Recognize patterns distinguishing steering-capable features from others.

Using a model with existing trained SAEs allows us to quickly validate our idea within the project's timeframe.

## References